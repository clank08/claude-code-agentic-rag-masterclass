# Module 1: App Shell + Observability

⚠️ **Medium** — Many files but well-known patterns. Execute in task order.

## Context

This is the first module of the RAG masterclass. We're building the foundational app shell: authentication, a chat UI with threaded conversations, and OpenAI's Responses API for managed RAG (black-box — OpenAI handles memory and retrieval). LangSmith provides observability from day one.

**Key architectural note:** The Responses API has no "threads" — conversations are chained via `previous_response_id`. Our `threads` table is our own abstraction that stores the last response ID per conversation.

Module 2 will replace the Responses API with the standard Chat Completions API for provider flexibility.

---

## Task 1: Project Scaffolding

### 1a. Backend setup
- Create `backend/` directory with this structure:
  ```
  backend/
    .env.example
    .gitignore          # venv/, .env, __pycache__/, *.pyc
    requirements.txt
    app/
      __init__.py
      main.py
      config.py
      dependencies.py
      middleware/
        __init__.py
        auth.py
      routers/
        __init__.py
        chat.py
        threads.py
      services/
        __init__.py
        openai_service.py
        langsmith_service.py
      models/
        __init__.py
        schemas.py
      database/
        __init__.py
        supabase_client.py
  ```
- Create venv: `python -m venv venv`
- Install dependencies via `requirements.txt`:
  ```
  fastapi
  uvicorn[standard]
  sse-starlette
  openai
  supabase
  PyJWT
  langsmith
  pydantic-settings
  httpx
  ```
- `pip freeze > requirements.txt` after install to pin versions

### 1b. Frontend setup
- Scaffold: `npm create vite@latest frontend -- --template react-ts`
- Install Tailwind: `npm install tailwindcss @tailwindcss/vite`
- Configure path aliases (`@/` → `./src/*`) in `tsconfig.json`, `tsconfig.app.json`, and `vite.config.ts`
- Init shadcn/ui: `npx shadcn@latest init` (New York style, Neutral, CSS variables)
- Install components in one batch:
  ```
  npx shadcn@latest add button input label card separator scroll-area avatar dropdown-menu sidebar tooltip
  ```
- Install additional deps: `npm install react-router-dom @supabase/supabase-js lucide-react`

### 1c. Environment variables
- `backend/.env.example`:
  ```
  OPENAI_API_KEY=
  OPENAI_MODEL=gpt-4.1
  SUPABASE_URL=
  SUPABASE_SERVICE_ROLE_KEY=
  SUPABASE_JWT_SECRET=
  LANGSMITH_API_KEY=
  LANGSMITH_PROJECT=rag-masterclass
  FRONTEND_URL=http://localhost:5173
  ```
- `frontend/.env.example`:
  ```
  VITE_SUPABASE_URL=
  VITE_SUPABASE_ANON_KEY=
  VITE_API_URL=http://localhost:8000
  ```
- Create actual `.env` files (gitignored) with real values

**Validate:** Backend — `python -c "import fastapi, openai, langsmith; print('OK')"`. Frontend — `npm run dev` starts at localhost:5173.

---

## Task 2: Database Schema

Run in Supabase SQL Editor:

```sql
create extension if not exists "uuid-ossp";

create table public.threads (
    id uuid primary key default uuid_generate_v4(),
    user_id uuid not null references auth.users(id) on delete cascade,
    openai_response_id text,  -- last response ID in chain (null until first message)
    title text not null default 'New Chat',
    created_at timestamptz not null default now(),
    updated_at timestamptz not null default now()
);

create index idx_threads_user_id on public.threads(user_id);

alter table public.threads enable row level security;

create policy "Users can view their own threads"
    on public.threads for select using (auth.uid() = user_id);
create policy "Users can create their own threads"
    on public.threads for insert with check (auth.uid() = user_id);
create policy "Users can update their own threads"
    on public.threads for update
    using (auth.uid() = user_id) with check (auth.uid() = user_id);
create policy "Users can delete their own threads"
    on public.threads for delete using (auth.uid() = user_id);

create or replace function public.update_updated_at_column()
returns trigger as $$
begin
    new.updated_at = now();
    return new;
end;
$$ language plpgsql;

create trigger update_threads_updated_at
    before update on public.threads
    for each row execute function public.update_updated_at_column();
```

**Note:** RLS policies use `auth.uid()` for direct DB access. Our backend uses the service role key (bypasses RLS), so it must filter by `user_id` explicitly in all queries.

**Validate:** Table visible in Supabase Table Editor with RLS shield icon active.

---

## Task 3: Backend Core

### 3a. Config (`app/config.py`)
- Pydantic `BaseSettings` loading from `.env`
- Fields: `openai_api_key`, `openai_model`, `supabase_url`, `supabase_service_role_key`, `supabase_jwt_secret`, `langsmith_api_key`, `langsmith_project`, `frontend_url`

### 3b. Supabase client (`app/database/supabase_client.py`)
- Initialize with service role key: `create_client(url, service_role_key)`

### 3c. Auth middleware (`app/middleware/auth.py`)
- FastAPI dependency using `HTTPBearer`
- Decode JWT with PyJWT: `jwt.decode(token, jwt_secret, algorithms=["HS256"], audience="authenticated")`
- Extract `sub` (user_id) and `email` from payload
- Return `AuthenticatedUser` Pydantic model
- Raise 401 for expired/invalid tokens

### 3d. Pydantic schemas (`app/models/schemas.py`)
- `ChatRequest`: `message` (str), `thread_id` (str | None)
- `ThreadResponse`: `id`, `title`, `created_at`, `updated_at`
- `AuthenticatedUser`: `id`, `email`

**Validate:** `python -c "from app.config import settings; print(settings.supabase_url)"`

---

## Task 4: LangSmith + OpenAI Integration

### 4a. LangSmith setup (`app/services/langsmith_service.py`)
- Set env vars in `app/main.py` before imports: `LANGSMITH_TRACING=true`, `LANGSMITH_API_KEY`, `LANGSMITH_PROJECT`
- Use `wrap_openai` from `langsmith.wrappers` to auto-instrument the OpenAI client
- Use `@traceable` decorator on service functions for parent spans with metadata

### 4b. OpenAI service (`app/services/openai_service.py`)
- Use `AsyncOpenAI` wrapped with `wrap_openai` for clean async streaming
- Key function: `stream_chat_response(message, previous_response_id)` → async generator of events
- Call `client.responses.create(model=..., input=message, stream=True, previous_response_id=...)`
- Yield events: `response.output_text.delta` → text tokens, `response.completed` → done with response ID
- Omit `tools` parameter for now (no vector stores yet — file_search has nothing to search)

**Validate:** Standalone test calling OpenAI with a simple message and printing streamed events.

---

## Task 5: Backend API Endpoints

### 5a. Threads router (`app/routers/threads.py`)
- `GET /api/threads` — list user's threads, ordered by `updated_at` desc
- `POST /api/threads` — create thread (insert row with user_id and title)
- `DELETE /api/threads/{thread_id}` — delete thread (filter by user_id)
- All routes use `Depends(get_current_user)`

### 5b. Chat router (`app/routers/chat.py`)
- `POST /api/chat` — receive message + optional thread_id
  - If `thread_id`: look up thread, get `openai_response_id`
  - If no `thread_id`: auto-create thread with message preview as title
  - Stream OpenAI response via `EventSourceResponse` (sse-starlette)
  - SSE events: `text_delta` (token), `done` (response_id + thread_id), `error`
  - After stream completes: update thread's `openai_response_id`
- Add headers: `X-Accel-Buffering: no`, `Cache-Control: no-cache`

### 5c. App assembly (`app/main.py`)
- Create FastAPI app
- Add CORS middleware (allow `frontend_url`, credentials, all methods/headers)
- Mount chat and threads routers
- Add `GET /api/health` (unauthenticated)
- Global exception handlers for OpenAI errors

**Validate:**
```bash
uvicorn app.main:app --reload --port 8000
curl http://localhost:8000/api/health  # → {"status": "ok"}
curl http://localhost:8000/docs        # Swagger UI
```

---

## Task 6: Frontend Auth

### 6a. Supabase client (`src/lib/supabase.ts`)
- `createClient(VITE_SUPABASE_URL, VITE_SUPABASE_ANON_KEY)`

### 6b. Auth context (`src/contexts/auth-context.tsx`)
- Provides: `session`, `user`, `loading`, `signIn`, `signUp`, `signOut`
- Uses `onAuthStateChange` for session tracking (keep callback synchronous — no await inside)
- `loading` state prevents flash of login page on refresh

### 6c. Auth pages
- `LoginPage` — email + password form, error display, link to signup
- `SignupPage` — same pattern, calls `signUp`, shows "check your email" on success
- `AuthLayout` — centered card wrapper using shadcn Card

### 6d. Router (`src/router.tsx`)
- `ProtectedRoute` — redirects to `/login` if no session
- `PublicRoute` — redirects to `/` if already logged in
- Routes: `/login`, `/signup`, `/` (chat, no thread selected), `/thread/:threadId` (chat with thread)

**Validate:** Unauthenticated → redirected to login. Sign up → check email. Log in → redirected to `/`.

---

## Task 7: Frontend Chat UI

### 7a. API helper (`src/lib/api.ts`)
- `apiGet`, `apiPost`, `apiDelete` — fetch wrappers that attach `Authorization: Bearer <token>` from Supabase session
- `apiStream` — returns raw `Response` for SSE (fetch with POST, not EventSource, because we need auth headers + POST body)

### 7b. SSE utility (`src/lib/sse.ts`)
- `readSSEStream(response, { onToken, onDone, onError })` — reads `response.body` via `ReadableStream.getReader()`
- Buffers partial lines, parses `data: ...` format
- Handles `[DONE]` sentinel or named events from backend

### 7c. Hooks
- `useThreads` — fetch/create/delete threads via API, returns `{ threads, createThread, deleteThread }`
- `useChat(threadId)` — manages `messages` array + `streamingContent` string + `sendMessage` function
  - User message added optimistically before API responds
  - During streaming: tokens accumulate in `streamingContent`
  - On done: full message committed to `messages`, `streamingContent` cleared

### 7d. Layout
- `AppLayout` — shadcn `SidebarProvider` + `Sidebar` + main content area
- `SidebarThreads` — "New Chat" button, thread list, user email + sign out
- `ThreadItem` — thread entry with active highlight, hover-reveal delete button

### 7e. Chat components
- `ChatPage` — orchestrates messages + composer for current `threadId` from URL params
- `MessageList` — scrollable message container with auto-scroll on new content
- `MessageBubble` — single message with role-based styling (user: primary, assistant: muted)
- `StreamingMessage` — assistant message with growing text + pulsing cursor
- `MessageComposer` — auto-resizing textarea, Enter to send, Shift+Enter for newline
- `EmptyState` — shown when no thread selected

### 7f. Types (`src/types/index.ts`)
- `Thread`: `id`, `title`, `created_at`, `updated_at`
- `Message`: `id`, `thread_id`, `role`, `content`, `created_at`

**Validate:** Create a thread → sends message → tokens stream in real-time → message completes → thread title shows in sidebar.

---

## Task 8: Integration Testing & Cleanup

- End-to-end test: sign up → create thread → send message → see streaming response → switch threads → sign out
- Verify LangSmith dashboard shows traces with user_id and thread_id metadata
- Clean up Vite boilerplate (default App.css, react.svg, counter code)
- Verify `.gitignore` excludes `node_modules/`, `dist/`, `.env`, `venv/`, `__pycache__/`
- Verify `npm run build` succeeds (no TS errors)

---

## Important Gotchas

1. **Responses API ≠ Assistants API** — No thread/assistant objects in OpenAI. Conversations chain via `previous_response_id`. Our threads table is our own construct.
2. **Token billing** — Every chained response replays the full context. A 20-message thread bills all 20 messages as input tokens each time.
3. **Service role key bypasses RLS** — Backend must explicitly filter by `user_id` on every query.
4. **JWT secret** — Found in Supabase dashboard → Project Settings → API → JWT Settings. Most cloud projects use HS256.
5. **SSE + POST** — Browser's native `EventSource` only supports GET. We use `fetch` + `ReadableStream` on the frontend.
6. **Supabase client is sync** — The `supabase-py` library blocks the event loop. Acceptable for Module 1's simple queries; can wrap with `asyncio.to_thread()` later if needed.
7. **CORS** — Frontend at `:5173` calling backend at `:8000` requires CORS middleware configured on the backend.
